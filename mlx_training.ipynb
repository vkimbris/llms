{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.mlx.models.gpt_mlx import GPT\n",
    "from src.mlx.models.gpt_mlx import generate_attention_mask\n",
    "from src.mlx.models.gpt_mlx import GPTParams\n",
    "from src.mlx.utils.mlx_lm_dataset import LanguageModelingDataset\n",
    "\n",
    "from src.tokenizers.tokenizer import Tokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_pretrained(\"tokenizers/tokenizer_ru_toxics/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = GPTParams(\n",
    "    vocab_size=len(tokenizer.vocab),\n",
    "    context_size=128,\n",
    "    input_dim=312,\n",
    "    query_dim=32,\n",
    "    value_dim=32,\n",
    "    feed_forward_hidden_dim=1024,\n",
    "    n_heads=4,\n",
    "    n_decoder_blocks=6,\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 2\n",
    "LEARNING_RATE = 2e-5\n",
    "MASK = generate_attention_mask(params.context_size - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.load(\"preprocessed_datasets/ru_toxics_tokens\")\n",
    "tokens = mx.array(tokens.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LanguageModelingDataset(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(model, inputs, labels):\n",
    "    logits = model(inputs, MASK)\n",
    "    logits = logits.reshape(-1, logits.shape[2])\n",
    "    \n",
    "    return mx.mean(nn.losses.cross_entropy(logits, labels.flatten()))\n",
    "\n",
    "optimizer = optim.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.eval(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b18f74953934b70827e9bed0e02955e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1704bb2dca404448885f9124c8bb0fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7960269010c48ed9dd661d1c9c2f301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/416 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "    for batch in tqdm(dataset.to_dataloader(batch_size=BATCH_SIZE), total=np.ceil(len(dataset) / BATCH_SIZE).astype(int)):\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = mx.array(inputs), mx.array(labels)\n",
    "\n",
    "        loss, grads = loss_and_grad_fn(model, inputs, labels)\n",
    "\n",
    "        optimizer.update(model, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
